# ğŸ¤– AI Chatbot

Welcome to the AI Chatbot project! This chatbot is powered by **Telegram** and **Hugging Face** AI models, providing smart, human-like responses to messages. Perfect for adding conversational AI to your Telegram bot or experimenting with AI-driven interactions!

## ğŸ“‚ Project Structure

- **main.py**: ğŸ›ï¸ This is the botâ€™s main control file, where the bot is initialized, message handling is defined, and responses are managed.
- **chatbot_AI.py**: ğŸ§  The brain of the chatbot! Contains AI response logic using Hugging Faceâ€™s Inference API.
- **requirements.txt**: ğŸ“¦ A list of dependencies required for the project to run smoothly.
- **Procfile**: ğŸ“„ Configuration for deployment (suitable for platforms like Heroku).
- **.gitignore**: ğŸš« Excludes unnecessary files, such as virtual environments, cached files, and configuration files containing sensitive information.

## âœ¨ Features

- **AI-Powered Responses**: Delivers interactive, human-like responses using a Hugging Face model.
- **Error Handling**: Ensures seamless interaction with user-friendly messages if errors occur.
- **Customizable Prompts**: Adjust the bot's tone and style with custom prompts.
- **Telegram Integration**: Connects easily with Telegram to handle user messages and provide replies.

## ğŸš€ Getting Started

### âœ… Prerequisites

1. **Python 3.8+** is required for compatibility.
2. Install project dependencies with:
    
   ```bash
   pip install -r requirements.txt
   ```
   
## ğŸ” Environment Setup
### API Keys:
#### Obtain your Hugging Face API key and Telegram bot token.
#### Environment Variables:
#### Create a config.py file at the project root.
#### Inside config.py, define:

- **BOT_TOKEN** = 'your-telegram-bot-token'
- **API_Key** = 'your-hugging-face-api-key'

## ğŸƒ Running the Bot
### To start the bot on your local machine, simply run:

```bash
python main.py
```

Alternatively, for deployment on platforms that support Procfile (like Heroku), follow these steps to deploy the bot to the cloud.

## ğŸ› ï¸ Configuration
#### The bot uses the Hugging Face tiiuae/falcon-7b-instruct model for response generation. You can customize the model settings by adjusting the parameters in chatbot_AI.py. Hereâ€™s a quick guide:

- **max_new_tokens**: Controls response length.
- **temperature**: Adjusts creativity; higher values yield more diverse responses.
- **top_p**: Controls the range of vocabulary for response selection.
### Example of generating a response:

   ```bash
response = client.text_generation(
    prompt="Hello, how can I help you?",
    max_new_tokens=150,
    temperature=0.85,
    top_p=0.9
)
 ```

## ğŸ¤– Response Management
### The AI response is refined to keep the conversation smooth:

The response generator removes unnecessary labels and formatting.
If the response is empty or unclear, a friendly default message is sent to keep the user engaged.

## ğŸ§© Example Usage
### To try out the chatbot:

- **Start a conversation**: Message the bot on Telegram.
- **Chat**: Type in any message; the bot will respond based on the AI modelâ€™s output.
- **Error-Free Communication**: The bot gracefully handles errors and logs them for easy troubleshooting.

## ğŸ› ï¸ Deployment
- **Procfile**: Ensure that your deployment platform supports Procfiles.
- **Example**: worker: python main.py will start the bot automatically.
- **Secure API Management**: Make sure API keys are securely managed (e.g., using environment variables).

## âš™ï¸ Project Dependencies
### The bot relies on several Python packages:

- **aiogram**: Handles Telegram interactions.
- **huggingface_hub**: Connects to the Hugging Face API for AI model integration.
- **python-dotenv**: Manages environment variables for secure API key storage.

### To install all dependencies, run:

```bash
pip install -r requirements.txt
```

## ğŸ“ License
This project is licensed under the MIT License.
